# EchoVault Entry Data Schema

This document describes every field stored for journal entries, including where each field comes from, how it's calculated, and when it's populated.

---

## Table of Contents

1. [Core Fields](#core-fields)
2. [Environment Context](#environment-context)
3. [Health Context](#health-context)
4. [Voice Tone Analysis](#voice-tone-analysis)
5. [Local Analysis](#local-analysis)
6. [Server Analysis](#server-analysis)
7. [Classification](#classification)
8. [Entity Resolution](#entity-resolution)
9. [Temporal Context](#temporal-context)
10. [Safety Flags](#safety-flags)
11. [Offline/Sync Fields](#offlinesync-fields)

---

## Core Fields

These fields are set at the moment of entry creation in `App.jsx:853-862`.

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `id` | `string` | Firestore | Auto-generated document ID when entry is saved |
| `text` | `string` | User input | The raw journal entry text (from text input or voice transcription) |
| `category` | `'work'` \| `'personal'` | User selection | Selected by user in the journal input UI; defaults based on user preference |
| `userId` | `string` | Firebase Auth | `auth.currentUser.uid` - identifies the entry owner |
| `createdAt` | `Timestamp` | System clock | `Timestamp.now()` at the moment of save |
| `effectiveDate` | `Timestamp` | Calculated | Usually same as `createdAt`, but backdated if temporal context detects past reference (e.g., "yesterday was rough") |
| `analysisStatus` | `'pending'` \| `'complete'` \| `'failed'` | System | Starts as `'pending'`, updated by Cloud Function after analysis |
| `signalExtractionVersion` | `number` | System | Starts at `1`, incremented on edits for race condition handling in signal extraction |
| `embedding` | `number[768]` \| `null` | Gemini API | 768-dimensional vector from `text-embedding-004` model; generated by Cloud Function trigger `onEntryCreate` |

### Embedding Generation

**Source**: `functions/index.js:914-950`

```
Entry created → onEntryCreate trigger → generateEmbeddingInternal()
  → POST to https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent
  → Returns 768-dimension float array
  → Cached by content hash in embedding_cache collection
```

The embedding enables semantic search and finding related entries.

---

## Environment Context

**Source**: `src/services/environment/environmentService.js:181-236`

Captured automatically at entry creation if location permission is granted. Contains weather, location, and light data for mood correlation analysis.

```javascript
entry.environmentContext = { ... }
```

### Location

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `location.latitude` | `number` | Capacitor Geolocation | Device GPS latitude, **rounded to 2 decimal places** (~1.1km precision) for privacy |
| `location.longitude` | `number` | Capacitor Geolocation | Device GPS longitude, rounded to 2 decimals |
| `location.cached` | `boolean` | System | `true` if retrieved from location cache (24hr TTL), `false` if fresh GPS reading |

**Privacy Note**: Coordinates are intentionally imprecise. `Math.round(lat * 100) / 100` gives ~1km accuracy.

**No `type` field exists** for location. Location is raw coordinates only—semantic place types (home, work, etc.) are handled separately as `place` entities in the memory graph.

### Point-in-Time Weather

Captured from Open-Meteo API at the exact moment of entry creation.

| Field | Type | Source | Calculation |
|-------|------|--------|-------------|
| `weather` | `string` \| `null` | Open-Meteo API | WMO weather code mapped to condition string: `'clear'`, `'partly_cloudy'`, `'cloudy'`, `'fog'`, `'drizzle'`, `'rain'`, `'snow'`, `'thunderstorm'` |
| `weatherLabel` | `string` \| `null` | Open-Meteo API | Human-readable: `'Clear sky'`, `'Light rain'`, `'Heavy snow'`, etc. |
| `temperature` | `number` \| `null` | Open-Meteo API | Current temperature at location |
| `temperatureUnit` | `'°F'` \| `'°C'` | User preference | Defaults to `'°C'`, configurable in settings |
| `cloudCover` | `number` \| `null` | Open-Meteo API | Cloud coverage percentage 0-100 |
| `isDay` | `boolean` | Open-Meteo API | `true` during daylight hours, `false` at night (based on sun position) |

### Day Summary

Fetched separately from Open-Meteo historical endpoint. More useful for correlation than point-in-time.

**Source**: `environmentService.js:192-209` via `getDailyWeatherHistory()`

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `daySummary.condition` | `string` | Open-Meteo | Dominant weather condition for the entire day |
| `daySummary.conditionLabel` | `string` | Open-Meteo | Human-readable day condition |
| `daySummary.tempHigh` | `number` | Open-Meteo | Day's maximum temperature |
| `daySummary.tempLow` | `number` | Open-Meteo | Day's minimum temperature |
| `daySummary.sunshineMinutes` | `number` | Open-Meteo | Total minutes of direct sunshine |
| `daySummary.sunshinePercent` | `number` | Calculated | `sunshineMinutes / (daylightHours * 60) * 100` |
| `daySummary.isLowSunshine` | `boolean` | Calculated | `true` if `sunshinePercent < 30%` (relevant for SAD correlation) |

### Sun Times & Light Context

**Source**: `environmentService.js:223-231`

| Field | Type | Source | Calculation |
|-------|------|--------|-------------|
| `sunsetTime` | `string` \| `null` | Open-Meteo | ISO time string for local sunset |
| `sunriseTime` | `string` \| `null` | Open-Meteo | ISO time string for local sunrise |
| `daylightHours` | `number` \| `null` | Calculated | Hours between sunrise and sunset |
| `daylightRemaining` | `number` \| `null` | Calculated | Hours until sunset (or `null` if after dark) |
| `isAfterDark` | `boolean` | Calculated | `isAfterSunset(sunTimes, now) \|\| isBeforeSunrise(sunTimes, now)` |
| `lightContext` | `string` | Calculated | See below |

**`lightContext` calculation** (`environmentService.js:145-152`):
```javascript
if (afterSunset || beforeSunrise) → 'dark'
else if (weather?.isLowLight) → 'low_light'  // Overcast/heavy clouds
else if (daylightRemaining < 2) → 'fading'   // Within 2 hours of sunset
else → 'daylight'
```

### Metadata

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `capturedAt` | `string` | System | ISO timestamp when environment context was captured |
| `backfilled` | `boolean` | Backfill service | `true` if weather was filled retroactively for older entries |
| `backfilledAt` | `string` | Backfill service | ISO timestamp of when backfill occurred |

---

## Health Context

**Source**: `src/services/health/healthDataService.js:274-350`

Captured automatically at entry creation if health integration is connected (Apple HealthKit, Google Fit, or Whoop).

```javascript
entry.healthContext = { ... }
```

### Sleep Data

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `sleep.sleepLastNight` | `number` \| `null` | HealthKit/Whoop | Total sleep hours from previous night |
| `sleep.sleepScore` | `number` \| `null` | Whoop only | Whoop's proprietary sleep performance score (0-100) |
| `sleep.sleepQuality` | `string` \| `null` | Calculated | `'poor'` (<6hrs or score<60), `'good'` (6-8hrs or 60-80), `'excellent'` (>8hrs or >80) |
| `sleep.sleepStages.deep` | `number` \| `null` | HealthKit/Whoop | Minutes in deep sleep |
| `sleep.sleepStages.rem` | `number` \| `null` | HealthKit/Whoop | Minutes in REM sleep |
| `sleep.sleepStages.light` | `number` \| `null` | HealthKit/Whoop | Minutes in light sleep |
| `sleep.sleepStages.awake` | `number` \| `null` | HealthKit/Whoop | Minutes awake during sleep period |

### Heart & HRV

| Field | Type | Source | Calculation |
|-------|------|--------|-------------|
| `heart.restingRate` | `number` \| `null` | HealthKit/Whoop | Resting heart rate (bpm), typically from morning reading |
| `heart.currentRate` | `number` \| `null` | HealthKit | Most recent heart rate reading |
| `heart.hrv` | `number` \| `null` | HealthKit/Whoop | Heart Rate Variability in milliseconds (RMSSD or SDNN) |
| `heart.stressIndicator` | `'low'` \| `'moderate'` \| `'high'` \| `null` | Calculated | Based on HRV thresholds |

**`stressIndicator` calculation** (`healthKit.js:235`):
```javascript
function calculateStressFromHRV(hrv) {
  if (hrv >= 50) return 'low';      // Good recovery/low stress
  if (hrv >= 30) return 'moderate'; // Normal range
  return 'high';                     // Elevated stress
}
```

### Recovery (Whoop only)

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `recovery.score` | `number` \| `null` | Whoop API | Recovery percentage 0-100 |
| `recovery.status` | `'red'` \| `'yellow'` \| `'green'` \| `null` | Whoop API | Red (<34%), Yellow (34-66%), Green (>66%) |

### Strain (Whoop only)

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `strain.score` | `number` \| `null` | Whoop API | Day strain 0-21 scale |
| `strain.maxHeartRate` | `number` \| `null` | Whoop API | Peak heart rate during strain activities |

### Activity

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `activity.stepsToday` | `number` \| `null` | HealthKit/Google Fit | Total steps since midnight. Whoop estimates from calories if no native step data |
| `activity.totalCaloriesBurned` | `number` \| `null` | Whoop/HealthKit | Total calories (BMR + active) |
| `activity.activeCaloriesBurned` | `number` \| `null` | Whoop/HealthKit | Calories from activity only |
| `activity.totalExerciseMinutes` | `number` \| `null` | HealthKit/Whoop | Minutes classified as exercise |
| `activity.hasWorkout` | `boolean` | All sources | `true` if any workout detected today |
| `activity.workouts` | `array` | All sources | Array of workout objects |

**Workout object**:
```javascript
{
  type: string,        // 'running', 'cycling', 'strength', 'yoga', etc.
  duration: number,    // Minutes
  distance: number,    // Meters (if applicable)
  calories: number,    // Calories burned
  source: 'whoop' | 'healthkit' | 'googlefit'
}
```

### Data Source Priority

When multiple sources are connected, data is merged with this priority (`healthDataService.js:121-147`):

| Metric | Primary Source | Fallback |
|--------|----------------|----------|
| Sleep score | Whoop | HealthKit stages analysis |
| HRV | Whoop | HealthKit |
| Steps | HealthKit | Google Fit |
| Calories | Whoop (strain-based) | HealthKit |
| Workouts | Merged from all sources | — |

---

## Voice Tone Analysis

**Source**: `relay-server/src/analysis/voiceTone.ts:65-138`

Only present for voice entries. Analyzed by Gemini from the raw audio recording.

```javascript
entry.voiceTone = { ... }
```

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `voiceTone.moodScore` | `number` | Gemini API | 0-1 scale. 0 = very distressed/negative, 1 = very positive/joyful |
| `voiceTone.energy` | `'low'` \| `'medium'` \| `'high'` | Gemini API | Energy level detected from voice pace, volume, pitch variation |
| `voiceTone.emotions` | `string[]` | Gemini API | Array of detected emotions: `['anxious', 'hopeful', 'tired']`. Max 5 emotions |
| `voiceTone.confidence` | `number` | Gemini API | 0-1 confidence in the analysis. Higher with longer, clearer audio |
| `voiceTone.summary` | `string` | Gemini API | One-sentence description: "User sounds tired but cautiously optimistic" |
| `voiceTone.analyzedAt` | `Timestamp` | System | When analysis was performed |
| `voiceMoodScore` | `number` \| `null` | Conditional | Set at entry root level if `voiceTone.confidence >= 0.6` |

### How Voice Analysis Works

```
User ends voice session → relay-server receives audio buffer
  → Audio minimum 1 second (48,000 bytes at 24kHz 16-bit mono)
  → Convert PCM to WAV with headers
  → Send to Gemini with multimodal prompt
  → Gemini analyzes:
      - Voice characteristics (tone, pace, pitch, pauses)
      - Transcript content (if available)
  → Returns JSON with moodScore, energy, emotions, confidence, summary
  → Values clamped to valid ranges
  → Sent to client as 'session_analysis' message
```

**Prompt used** (voiceTone.ts:85-99):
```
Analyze the emotional tone and mood from this voice recording. Focus on:
1. The speaker's emotional state based on voice characteristics (tone, pace, pitch variations, pauses)
2. Energy level (low/medium/high)
3. Specific emotions you can detect
```

---

## Local Analysis

**Source**: `src/services/analysis/localSentiment.js`

Performed on-device (native platforms only) for immediate feedback before server analysis completes.

```javascript
entry.localAnalysis = { ... }
```

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `localAnalysis.entry_type` | `string` | Local classifier | `'task'`, `'mixed'`, `'reflection'`, or `'vent'` |
| `localAnalysis.mood_score` | `number` | VADER-style lexicon | 0-1 scale, lexicon-based sentiment analysis |
| `localAnalysis.classification_confidence` | `number` | Classifier | Confidence in entry_type classification |
| `localAnalysis.sentiment_confidence` | `number` | Lexicon analyzer | Confidence based on matched words and consistency |
| `localAnalysis.extracted_tasks` | `string[]` | Pattern matching | Task-like phrases detected (e.g., "need to...", "have to...") |
| `localAnalysis.analyzed_at` | `string` | System | ISO timestamp of analysis |
| `localAnalysis.analysis_time_ms` | `number` | System | How long analysis took (target <30ms) |
| `hasLocalAnalysis` | `boolean` | System | `true` if local analysis was performed |

### Local Sentiment Calculation

**Source**: `localSentiment.js:36-170`

Uses VADER-style lexicon approach:

1. **Tokenize** text into words
2. **Check context phrases** for compound expressions ("can't wait", "falling apart")
3. **Analyze emojis** for sentiment contribution
4. **For each word**:
   - Check if negator ("not", "never") → activate negation window (3 words)
   - Check for intensifier ("very", "extremely") → multiply sentiment strength
   - Look up word in lexicon → get base sentiment score
   - Apply negation (flip around 0.5 neutral point)
   - Apply intensifier (amplify distance from neutral)
5. **Weighted average** of all sentiment scores (more recent = slightly higher weight)
6. **Calculate confidence** from match count and score consistency

**Performance**: Target <30ms. No network calls, no AI dependency.

---

## Server Analysis

**Source**: `functions/index.js:387-610`

Performed by Cloud Functions after entry is saved. Provides rich therapeutic analysis.

```javascript
entry.analysis = { ... }
entry.entry_type = '...'
entry.title = '...'
```

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `entry_type` | `string` | Gemini classification | `'task'`, `'mixed'`, `'reflection'`, `'vent'` |
| `title` | `string` | Gemini analysis | AI-generated title (max 6 words) |
| `analysis.mood_score` | `number` | Gemini analysis | 0-1 scale with therapeutic routing logic |
| `analysis.framework` | `string` | Gemini analysis | Therapeutic framework: `'cbt'`, `'act'`, `'celebration'`, `'general'` |
| `analysis.tags` | `string[]` | Gemini analysis | Relevant tags for the entry |

### Mood Score Guidelines

The AI is instructed with specific routing logic (`functions/index.js:496-499`):

| Mood Score | Label | AI Response Strategy |
|------------|-------|---------------------|
| 0.6+ | Positive/Neutral | Light response - validation or affirmation only |
| 0.4-0.6 | Mixed | Medium response - add perspective if helpful |
| 0.2-0.4 | Struggling | Full response - behavioral suggestions, committed action |
| <0.2 | Distressed | Full response + always include behavioral_activation or committed_action |

### Framework-Specific Analysis

#### CBT Framework (`analysis.cbt_breakdown`)

| Field | Type | Description |
|-------|------|-------------|
| `automatic_thought` | `string` \| `null` | The negative thought pattern identified |
| `distortion` | `string` \| `null` | Cognitive distortion label (catastrophizing, all-or-nothing, etc.) |
| `validation` | `string` | Empathetic acknowledgment (1-2 sentences) - always included |
| `perspective` | `string` \| `null` | Question + alternative reframe. Only if mood < 0.5 |
| `behavioral_activation.activity` | `string` | Simple 5-minute activity appropriate for time of day |
| `behavioral_activation.rationale` | `string` | One sentence explaining why it helps |

#### ACT Framework (`analysis.act_analysis`)

| Field | Type | Description |
|-------|------|-------------|
| `acknowledgment` | `string` | Warm validation of difficult feelings (1-2 sentences) |
| `fusion_thought` | `string` | The thought user is "fused" with (treating as absolute truth) |
| `defusion_technique` | `string` | `'labeling'`, `'visualization'`, or `'thanking_mind'` |
| `defusion_phrase` | `string` | Specific phrase for the technique |
| `values_context` | `string` | Core value at stake (Connection, Growth, Health, etc.) |
| `committed_action` | `string` | Tiny concrete step (<5 min) aligned with values |

#### Celebration Framework (`analysis.celebration`)

| Field | Type | Description |
|-------|------|-------------|
| `affirmation` | `string` | Warm acknowledgment of positive moment |
| `amplify` | `string` \| `null` | Prompt to savor or deepen the feeling |

#### Other Analysis Fields

| Field | Type | Description |
|-------|------|-------------|
| `task_acknowledgment` | `string` \| `null` | Empathetic note about to-do list load |

### Analysis Flow

```
Entry saved with analysisStatus: 'pending'
  → User calls analyzeJournalEntryFn (or onEntryCreate trigger)
  → classifyEntry() determines entry_type
  → analyzeEntry() with entry_type and user's local hour
  → Gemini generates title, tags, mood_score, framework, framework-specific analysis
  → Entry updated with analysisStatus: 'complete'
```

---

## Classification

**Source**: `functions/index.js:296-382`

Separate from analysis—determines what type of entry this is.

```javascript
entry.classification = { ... }
```

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `classification.entry_type` | `string` | Gemini | `'task'`, `'mixed'`, `'reflection'`, `'vent'` |
| `classification.confidence` | `number` | Gemini | 0-1 confidence in classification |
| `classification.extracted_tasks` | `string[]` | Gemini | Specific task items found in entry |

### Entry Type Definitions

| Type | Description | Example |
|------|-------------|---------|
| `task` | Primarily about to-do items, planning, logistics | "Need to call the dentist and pick up groceries" |
| `mixed` | Combination of tasks and emotional content | "Feeling overwhelmed. Need to finish the report by Friday" |
| `reflection` | Emotional processing, self-examination, insights | "I've been thinking about why I get anxious in meetings" |
| `vent` | Emotional release, frustration, distress | "I can't believe my boss said that. So frustrated right now" |

---

## Entity Resolution

**Source**: `functions/index.js:850-882`

Corrects entity names in entry text based on user's known entities.

```javascript
entry.entityResolution = { ... }  // Only present if corrections were made
```

| Field | Type | Description |
|-------|------|-------------|
| `entityResolution.originalText` | `string` | The entry text before correction |
| `entityResolution.correctedText` | `string` | Text after entity name corrections |
| `entityResolution.corrections` | `array` | Array of corrections made |
| `entityResolution.corrections[].original` | `string` | What was written ("sarah") |
| `entityResolution.corrections[].corrected` | `string` | Canonical name ("Sarah") |
| `entityResolution.corrections[].entityId` | `string` | ID of the matched entity |

### How Entity Resolution Works

```
Entry text: "had lunch with sarah today"
  → Look up user's entities
  → Find entity: { id: 'abc', name: 'Sarah', aliases: ['sarah', 'sar'] }
  → Correct: "had lunch with Sarah today"
  → Store correction record
```

---

## Temporal Context

**Source**: `src/services/temporal/index.js`

Detects when users reference past or future times.

### Past Reference Context

```javascript
entry.temporalContext = { ... }  // Only if past reference detected
```

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `temporalContext.detected` | `boolean` | Pattern matching + Gemini | Whether temporal reference was found |
| `temporalContext.reference` | `string` | Gemini extraction | Normalized reference: `'yesterday'`, `'last_monday'`, `'two_days_ago'` |
| `temporalContext.originalPhrase` | `string` | Gemini extraction | User's exact words: "the other day" |
| `temporalContext.confidence` | `number` | Gemini | 0-1 confidence in detection |
| `temporalContext.backdated` | `boolean` | Calculated | `true` if effectiveDate differs from createdAt |

**Date Calculation Examples** (`temporal/index.js:98-220`):

| Reference | Calculation |
|-----------|-------------|
| `yesterday` | `today - 1 day` |
| `last_night` | `today - 1 day` (unless before 6am, then `today`) |
| `two_days_ago` | `today - 2 days` |
| `last_monday` | Previous week's Monday |
| `this_monday` | This week's Monday (past if already passed) |
| `next_monday` | Next week's Monday |

### Future Mentions

```javascript
entry.futureMentions = [...]  // Only if future references detected
```

| Field | Type | Description |
|-------|------|-------------|
| `futureMentions[].targetDate` | `Timestamp` | When the mentioned event will occur |
| `futureMentions[].event` | `string` | What's happening: "interview", "meeting", "dentist appointment" |
| `futureMentions[].sentiment` | `string` | User's feeling about it: `'anxious'`, `'excited'`, `'dreading'` |
| `futureMentions[].phrase` | `string` | User's exact words |
| `futureMentions[].confidence` | `number` | Detection confidence |
| `futureMentions[].isRecurring` | `boolean` | `true` for recurring events |
| `futureMentions[].recurringPattern` | `string` \| `null` | Pattern: `'weekly'`, `'daily'`, `'every_monday'` |

**Purpose**: Enables proactive follow-up prompts. "You mentioned being nervous about your interview tomorrow. How did it go?"

---

## Safety Flags

**Source**: `src/config/constants.js:8-9`, `App.jsx:938-947`

Critical safety detection for crisis intervention.

```javascript
entry.safety_flagged = true;
entry.safety_user_response = '...';
entry.has_warning_indicators = true;
```

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `safety_flagged` | `boolean` | Regex matching | `true` if CRISIS_KEYWORDS pattern matched |
| `safety_user_response` | `string` | User input | User's response to safety prompt |
| `has_warning_indicators` | `boolean` | Regex matching | `true` if WARNING_INDICATORS pattern matched |

### Crisis Keywords (constants.js:8)

```javascript
const CRISIS_KEYWORDS = /suicide|kill myself|hurt myself|end my life|want to die|better off dead|no reason to live|end it all|don't want to wake up|better off without me/i;
```

**Triggers immediate intervention modal with crisis resources.**

### Warning Indicators (constants.js:9)

```javascript
const WARNING_INDICATORS = /hopeless|worthless|no point|can't go on|trapped|burden|no way out|give up|falling apart/i;
```

**Triggers softer check-in, not full crisis flow.**

---

## Offline/Sync Fields

**Source**: `src/services/sync/syncOrchestrator.js:145-156`

Present when entries are created offline and later synced.

| Field | Type | Source | Description |
|-------|------|--------|-------------|
| `offlineCreated` | `boolean` | Sync system | `true` if entry was created while offline |
| `offlineId` | `string` | Offline manager | UUID generated offline for deduplication |

### Sync Flow

```
Entry created offline
  → Stored in IndexedDB with offlineId
  → Network restored
  → syncOrchestrator detects pending entries
  → Uploads with offlineCreated: true, offlineId: 'xxx'
  → Server deduplicates by offlineId
  → Local IndexedDB entry marked as synced
```

---

## Data Flow Summary

```
┌─────────────────────────────────────────────────────────────────────────┐
│                           ENTRY CREATION                                 │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  User Input (text or voice)                                             │
│       │                                                                  │
│       ├── Voice? ──→ Relay Server ──→ Transcription + Voice Tone        │
│       │                                                                  │
│       ▼                                                                  │
│  [Parallel Context Capture]                                             │
│       ├── getEntryHealthContext() ──→ healthContext                     │
│       ├── getEntryEnvironmentContext() ──→ environmentContext           │
│       └── Local Analysis (native) ──→ localAnalysis                     │
│                                                                          │
│       ▼                                                                  │
│  [Safety Check]                                                          │
│       ├── CRISIS_KEYWORDS? ──→ safety_flagged                           │
│       └── WARNING_INDICATORS? ──→ has_warning_indicators                │
│                                                                          │
│       ▼                                                                  │
│  [Temporal Detection]                                                    │
│       ├── Past reference? ──→ Backdate effectiveDate                    │
│       └── Future reference? ──→ futureMentions[]                        │
│                                                                          │
│       ▼                                                                  │
│  Save to Firestore (analysisStatus: 'pending')                          │
│                                                                          │
├─────────────────────────────────────────────────────────────────────────┤
│                        POST-SAVE PROCESSING                              │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  [Firestore Trigger: onEntryCreate]                                     │
│       └── generateEmbeddingInternal() ──→ embedding                     │
│                                                                          │
│  [Client-side call: analyzeJournalEntryFn]                              │
│       ├── Entity Resolution ──→ entityResolution                        │
│       ├── classifyEntry() ──→ classification, entry_type                │
│       └── analyzeEntry() ──→ analysis, title                            │
│                                                                          │
│  [Client-side: processEntrySignals]                                     │
│       └── Signal extraction ──→ Saved to signal_states collection       │
│                                                                          │
│  analysisStatus: 'complete'                                             │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## Field Availability by Entry Type

| Context | Always Present | Conditionally Present |
|---------|---------------|----------------------|
| **All Entries** | id, text, category, userId, createdAt, effectiveDate, analysisStatus | — |
| **Text Entry** | — | temporalContext, futureMentions |
| **Voice Entry** | transcriptionText | voiceTone, voiceMoodScore |
| **With Location Permission** | — | environmentContext (all fields) |
| **With Health Integration** | — | healthContext (all fields) |
| **After Server Analysis** | entry_type, title, analysis | classification, entityResolution |
| **Native Platform** | — | localAnalysis |
| **Offline Entry** | — | offlineCreated, offlineId |
| **Safety Concern** | — | safety_flagged, safety_user_response, has_warning_indicators |
